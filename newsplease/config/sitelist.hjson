# This is a HJSON-File, so comments and so on can be used! See https://hjson.org/
# Furthermore this is first of all the actual config file, but as default just filled with examples.
{
  # Every URL has to be in an array-object in "base_urls".
  # The same URL in combination with the same crawler may only appear once in this array.
  "base_urls" : [
    {
      # Start crawling from faz.net
      "url": "https://www.nytimes.com/2017/02/22/us/politics/devos-sessions-transgender-students-rights.html?hp",

      # Overwrite the default crawler and use th RecursiveCrawler instead
      "crawler": "Download",
    }
  ]
}
